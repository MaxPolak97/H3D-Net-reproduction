{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84a52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h3ds.dataset import H3DS\n",
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "import trimesh\n",
    "import copy\n",
    "from ipywidgets import interact, interactive, widgets, fixed\n",
    "from h3ds.mesh import Mesh\n",
    "#from vtkplotter import *\n",
    "\n",
    "h3ds = H3DS(path='h3ds_v0.2')\n",
    "\n",
    "#h3ds.download(token= 4ce4d22168adeeefe6a1ec1d738fac4d) # This is currenly not working so please downlad the data manually\n",
    "#mesh, images, masks, cameras = h3ds.load_scene(scene_id='1b2a8613401e42a8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76d16e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = 'e98bae39fad2244e'\n",
    "view = '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "285f2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh_pred_path = 'idr_eval_results/reconstructions/idr/3b5a2eb92a501d54_3.ply'\n",
    "mesh_pred_path = 'idr_eval_results/reconstructions/idr/' + scene_id + '_' + view + '.ply'\n",
    "#print(mesh_pred_path)\n",
    "#mesh_gt_path = 'h3ds_v0.2/3b5a2eb92a501d54/full_head.obj'\n",
    "#mesh_SWC_path = 'surface_world_coordinates_2000.ply'\n",
    "\n",
    "#mesh_pred = trimesh.load(mesh_pred_path, process=False)\n",
    "mesh_pred = Mesh().load(mesh_pred_path)\n",
    "\n",
    "#mesh_gt = trimesh.load(mesh_gt_path, process=False)\n",
    "#mesh_gt, images, masks, cameras, _ = h3ds.load_scene('3b5a2eb92a501d54', '3')\n",
    "mesh_gt, images, masks, cameras, _ = h3ds.load_scene(scene_id, view)\n",
    "#mesh_SWC = trimesh.load(mesh_SWC_path, process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24aaff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -33.7601967   210.695465   -108.310646  ]\n",
      " [ -79.6126328   -63.1199799    47.1410408 ]\n",
      " [ -79.6280289   -62.9717941    46.3343849 ]\n",
      " ...\n",
      " [  77.4853058  -131.45816      29.3969536 ]\n",
      " [  57.9439278    82.7792358    46.1316833 ]\n",
      " [   7.57576561  158.293549    113.368912  ]]\n",
      "[[-300.95037842  359.82531738  152.52180481]\n",
      " [ 138.09741211  351.34289551  128.07264709]\n",
      " [ 273.12338257  319.11581421   28.54338646]\n",
      " ...\n",
      " [ -45.23747635  268.29058838  175.5375824 ]\n",
      " [  42.84520721  207.59204102 -175.0511322 ]\n",
      " [-131.78384399  116.43390656   22.11521339]]\n"
     ]
    }
   ],
   "source": [
    "#print(mesh_pred.centroid)\n",
    "#print(mesh_gt.centroid)\n",
    "#print(mesh_gt.extents)\n",
    "\n",
    "#print(mesh_pred.bounding_box.extents)\n",
    "\n",
    "#print(mesh_gt.vertices)\n",
    "\n",
    "vertices = mesh_gt.vertices\n",
    "vertices_pred = mesh_pred.vertices\n",
    "\n",
    "\n",
    "\n",
    "print(vertices)\n",
    "print(vertices_pred)\n",
    "\n",
    "#pc_gt = Points(mesh_gt.vertices, r=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c63a6637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-16.641, -33.323, -97.289], [16.017, -33.736, -94.226], [3.202, 17.111, -120.557], [-17.881, 32.82, -103.418], [20.151, 33.234, -101.577], [0.308, 0.576, -136.286]]\n",
      "[-300.95037842  359.82531738  152.52180481]\n"
     ]
    }
   ],
   "source": [
    "closest_vert_right_eye = vertices_pred[0]\n",
    "closest_vert_left_eye = vertices_pred[0]\n",
    "closest_vert_nose_base = vertices_pred[0]\n",
    "closest_vert_right_lips = vertices_pred[0]\n",
    "closest_vert_left_lips = vertices_pred[0]\n",
    "closest_vert_nose_tip = vertices_pred[0]\n",
    "\n",
    "closest_vert = [closest_vert_right_eye, \n",
    "                closest_vert_left_eye, \n",
    "                closest_vert_nose_base, \n",
    "                closest_vert_right_lips, \n",
    "                closest_vert_left_lips,\n",
    "                closest_vert_nose_tip]\n",
    "\n",
    "#print(closest_vert)\n",
    "#168f8ca5c2dce5bc\n",
    "#right_eye = [-64.928, -103.996, 552.295]\n",
    "#left_eye = [-37.282, -105.554, 563.712]\n",
    "#nose_base = [-47.800, -34.497, 542.937]\n",
    "#right_lips = [-84.489, 6.352, 558.372]\n",
    "#left_lips = [-13.259, 8.071, 561.263]\n",
    "#nose_tip = [-48.228, -65.305, 560.791]\n",
    "\n",
    "#7dd427509fe84baa_32\n",
    "#right_eye = []\n",
    "#left_eye = []\n",
    "#nose_base = []\n",
    "#right_lips = []\n",
    "#left_lips = []\n",
    "#nose_tip = []\n",
    "\n",
    "#1b2a8613401e42a8_32\n",
    "#right_eye = [-19.820, -32.081, -95.198]\n",
    "#left_eye = [17.733, -35.211, -94.272]\n",
    "#nose_base = [-2.217, 14.079, -113.702]\n",
    "#right_lips = [-25.297, 32.855, -102.144]\n",
    "#left_lips = [22.428, 33.638, -100.588]\n",
    "#nose_tip = [-1.435, -2.742, -131.073]\n",
    "\n",
    "#609cc60fd416e187_32\n",
    "#right_eye = [-16.530, -30.722, -89.802]\n",
    "#left_eye = [20.720, -30.001,  -87.447]\n",
    "#nose_base = [0.304, 20.138, -110.146]\n",
    "#right_lips = [-20.828, 38.404, -98.572]\n",
    "#left_lips = [27.883, 36.972, -94.766]\n",
    "#nose_tip = [2.811, 0.797, -123.518]\n",
    "\n",
    "#868765907f66fd85_32\n",
    "#right_eye = [-16.173, -35.793, -98.171]\n",
    "#left_eye = [14.203, -35.377, -95.532]\n",
    "#nose_base = [-1.193, 10.396, -114.209]\n",
    "#right_lips = [-24.079, 37.443, -102.910]\n",
    "#left_lips = [27.519, 39.107, -101.903]\n",
    "#nose_tip = [-2.441, -7.081, -128.065]\n",
    "\n",
    "#5cd49557ea450c89_32\n",
    "#right_eye = [-19.855, -29.891, -97.883]\n",
    "#left_eye = [16.004, -29.891, -95.568]\n",
    "#nose_base = [-2.106, 19.369, -114.213]\n",
    "#right_lips = [-28.185, 42.913, -99.448]\n",
    "#left_lips = [21.437, 44.724, -102.377]\n",
    "#nose_tip = [-2.106, 2.346, -128.631]\n",
    "\n",
    "#7dd427509fe84baa_32\n",
    "#right_eye = [-9.408, -35.940, -98.784]\n",
    "#left_eye = [21.971, -37.289, -90.242]\n",
    "#nose_base = [3.413, 8.261, -110.539]\n",
    "#right_lips = [-22.567, 36.603, -95.941]\n",
    "#left_lips = [27.032, 38.291, -93.944]\n",
    "#nose_tip = [6.113, -5.573, -129.971]\n",
    "\n",
    "#444ea0dc5e85ee0b_32\n",
    "#right_eye = [-16.579, -30.780, -86.765]\n",
    "#left_eye = [16.459, -31.846, -86,564]\n",
    "#nose_base = [-0.859, 12.649, -101.914]\n",
    "#right_lips = [-22.707, 34.230, -92.336]\n",
    "#left_lips = [20.189, 33.164, -92.723]\n",
    "#nose_tip = [-1.925, -4.136, -113.307]\n",
    "\n",
    "#f7e930d8a9ff2091_32\n",
    "#right_eye = [-13.089, -36.052, -85.997]\n",
    "#left_eye = [25.550, -34.916, -82.172]\n",
    "#nose_base = [6.231, 9.784, -106.997]\n",
    "#right_lips = [-25.211, 29.861, -91.883]\n",
    "#left_lips = [27.444, 30.240, -96.115]\n",
    "#nose_tip = [8.882, -7.641, -122.460]\n",
    "\n",
    "#e98bae39fad2244e_32\n",
    "right_eye = [-16.641, -33.323, -97.289]\n",
    "left_eye = [16.017, -33.736, -94.226]\n",
    "nose_base = [3.202, 17.111, -120.557]\n",
    "right_lips = [-17.881, 32.820, -103.418]\n",
    "left_lips = [20.151, 33.234, -101.577]\n",
    "nose_tip = [0.308, 0.576, -136.286]\n",
    "\n",
    "landmarks = [right_eye, left_eye, nose_base, right_lips, left_lips, nose_tip]\n",
    "\n",
    "\n",
    "print(landmarks)\n",
    "print(closest_vert[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d77bab82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.612102859497071, 1.840360214233396, 1.7448990364074692, 3.5131588897705015, 3.5776113586425815, 0.316243880271913]\n",
      "[940360, 60933, 945965, 677720, 761220, 923850]\n"
     ]
    }
   ],
   "source": [
    "closest_loss = []\n",
    "\n",
    "for idx, vertex in enumerate(closest_vert):\n",
    "    closest_loss.append(abs(vertex[0] - landmarks[idx][0]) + abs(vertex[1] - landmarks[idx][1]) + abs(vertex[2] - landmarks[idx][2]))\n",
    "\n",
    "#print(closest_loss)\n",
    "#closest_loss_right_eye = abs(closest_vert_right_eye[0] - right_eye[0]) + abs(closest_vert_right_eye[1] - right_eye[1]) + abs(closest_vert_right_eye[2] - right_eye[2])\n",
    "#closest_loss_left_eye = abs(closest_vert_left_eye[0] - left_eye[0]) + abs(closest_vert_left_eye[1] - left_eye[1]) + abs(closest_vert_left_eye[2] - left_eye[2])\n",
    "\n",
    "\n",
    "#print(closest_loss)\n",
    "landmarks_idx = [0, 0, 0, 0, 0, 0]\n",
    "#right_eye_idx = 0\n",
    "for idx_1, landmark in enumerate(landmarks):\n",
    "    for idx, vert in enumerate(vertices_pred):\n",
    "        loss = abs(vert[0] - landmark[0]) + abs(vert[1] - landmark[1]) + abs(vert[2] - landmark[2])\n",
    "        if loss < closest_loss[idx_1]:\n",
    "            closest_vert[idx_1] = vert\n",
    "            closest_loss[idx_1] = loss\n",
    "            landmarks_idx[idx_1] = idx\n",
    "        \n",
    "\n",
    "        \n",
    "print(closest_loss)\n",
    "\n",
    "print(landmarks_idx)\n",
    "#print(right_eye_idx)\n",
    "#print(\"Closest_vert: \",closest_vert)\n",
    "\n",
    "#right_eye_idx = np.where(vertices_pred == closest_vert)\n",
    "#print(vertices_pred[right_eye_idx])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0350d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = landmarks_idx\n",
    "keys = landmarks = ['right_eye', 'left_eye', 'nose_base', 'right_lips', 'left_lips', 'nose_tip']\n",
    "\n",
    "with open('idr_eval_results/reconstructions/idr/' + scene_id + '_' + 'landmarks' + '_' + view + '.txt', 'w') as f:\n",
    "    for idx, line in enumerate(lines):\n",
    "        f.write(keys[idx])\n",
    "        f.write(' ')\n",
    "        f.write(str(line))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c21b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = plt.axes(projection='3d')\n",
    "#ay = plt.axes(projection='3d')\n",
    "#ax = Axes3D(fig)\n",
    "ax.scatter(vertices[:,0],vertices[:,2], -(vertices[:,1]), s=0.01)#, markerfacecolor=\"blue\", markersize=0.01)\n",
    "#ax.scatter(vertices[381,0], vertices[381,2], -vertices[381,1])\n",
    "ax.scatter(vertices_pred[:,0],vertices_pred[:,2], -(vertices_pred[:,1]),  s=0.01)\n",
    "#ax.plot3D(vertices[140857,0], vertices[140857,2], -vertices[140857,1], marker=\"o\", markerfacecolor=\"yellow\", markersize=25)\n",
    "#ax.plot3D(vertices[669,0], vertices[669,2], -vertices[669,1], marker=\"o\", markerfacecolor=\"yellow\", markersize=25)\n",
    "#ax.plot3D(vertices[52158,0], vertices[52158,2], -vertices[52158,1], marker=\"o\", markerfacecolor=\"red\", markersize=25)\n",
    "#ax.plot3D(vertices[135155,0], vertices[135155,2], -vertices[135155,1], marker=\"o\", markerfacecolor=\"red\", markersize=25)\n",
    "#ax.plot3D(vertices[1348,0], vertices[1348,2], -vertices[1348,1], marker=\"o\", markerfacecolor=\"red\", markersize=25)\n",
    "#ax.plot3D(vertices[381,0], vertices[381,2], -vertices[381,1], marker=\"o\", markerfacecolor=\"green\", markersize=25)\n",
    "\n",
    "for idx in landmarks_idx:\n",
    "    ax.plot3D(vertices_pred[idx,0], vertices_pred[idx,2], -vertices_pred[idx,1], marker=\"o\", markerfacecolor=\"orange\", markersize=25)\n",
    "\n",
    "#ax.plot(vertices[669][0], vertices[669][2], -vertices[669][1], marker=\"o\", markerfacecolor=\"red\", markersize=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#from open3d import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#show((mesh_pred), axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047261e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh_gt.show()\n",
    "mesh_SWC.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale = mesh_pred.extents / mesh_gt.extents\n",
    "#matrix = np.eye(4)\n",
    "#matrix[:2, :2] /= scale[:2]\n",
    "#mesh_pred_copy = copy.deepcopy(mesh_pred)\n",
    "\n",
    "#mesh_pred_copy.apply_transform(matrix)\n",
    "\n",
    "#print('\\nafter operation\\n')\n",
    "#print(mesh_pred_copy.extents)\n",
    "#print(mesh_gt.extents)\n",
    "\n",
    "T, cost = trimesh.registration.mesh_other(mesh_pred, mesh_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4914ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh_pred_copy.show()\n",
    "#mesh_pred_trans.export('mesh_pred_trans.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T, cost = trimesh.registration.mesh_other(mesh_pred, mesh_gt)\n",
    "matrix = np.eye(4)\n",
    "P = mesh_gt.centroid - mesh_pred.centroid\n",
    "matrix[:,3] = [0, P[1], P[2], 1]\n",
    "print(matrix)\n",
    "mesh_pred_copy = copy.deepcopy(mesh_pred)\n",
    "mesh_pred_trans = mesh_pred_copy.apply_transform(matrix)\n",
    "\n",
    "print(mesh_pred_trans)\n",
    "#transformed_mesh = trimesh.transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98827f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T, cost = trimesh.registration.mesh_other(mesh_pred_trans, mesh_gt)\n",
    "#print(matrix)\n",
    "#print(T)\n",
    "\n",
    "print(mesh_pred_trans.centroid)\n",
    "print(mesh_gt.centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3bc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh_pred_trans = mesh_pred_trans.apply_transform(T)\n",
    "#print(T, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38495dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T, cost = trimesh.registration.mesh_other(mesh_pred_trans, mesh_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(T, cost)\n",
    "#print(mesh_pred_trans.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbb7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trimesh.exchange.export.export_mesh(mesh_pred_trans, 'mesh_pred_trans.ply')\n",
    "mesh_pred_trans.export('mesh_pred_trans.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee1bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = h3ds.scenes() # returns all the scenes ['1b2a8613401e42a8', ...]\n",
    "scenes = h3ds.scenes(tags={'h3d-net'}) # returns the scenes used in H3D-Net paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b254a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_configs = h3ds.default_views_configs(scene_id='1b2a8613401e42a8') # '3', '4', '8', '16' and '32'\n",
    "mesh_3, images_3, masks_3, cameras_3 = h3ds.load_scene(scene_id='1b2a8613401e42a8', views_config_id='3')\n",
    "mesh, images, masks, cameras = h3ds.load_scene(scene_id='1b2a8613401e42a8')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69455536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#views_config_id=3\n",
    "\n",
    "#print(\"This is the original loaded cameras.npz file with vc_id = 3: \\n\\n\", cameras_3)\n",
    "\n",
    "loaded_cameras = np.load('cameras.npz')\n",
    "\n",
    "loaded_cameras.files\n",
    "\n",
    "loaded_cameras['scale_mat_0']\n",
    "\n",
    "#print(\"This is the original loaded cameras.npz \\n\\n\", loaded_cameras)\n",
    "\n",
    "\n",
    "#outfile = TemporaryFile()\n",
    "#np.savez('cameras_reloaded', cameras)\n",
    "\n",
    "#loaded_cameras_reloaded = np.load('cameras_reloaded.npz')\n",
    "#loaded_cameras_3 = tuple(loaded_cameras_3.reshape(1, -1))\n",
    "#final_loaded_cameras_3 = ()\n",
    "#for idx in views_config_id:\n",
    "#    final_loaded_cameras_3.append()\n",
    "\n",
    "\n",
    "\n",
    "#print(\" \")\n",
    "#print(loaded_cameras_3)\n",
    "\n",
    "#print(loaded_cameras.files)\n",
    "#print(loaded_cameras_3.files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54530a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh_pred, landmarks_pred = my_rec_method(images, masks, cameras)\n",
    "chamfer, _, _, _ = h3ds.evaluate_scene('1b2a8613401e42a8', mesh_pred, landmarks_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from h3ds.dataset import H3DS\n",
    "from h3ds.mesh import Mesh\n",
    "from h3ds.log import logger\n",
    "from h3ds.utils import error_to_color, download_file_from_google_drive, create_parent_directory, create_directory, remove\n",
    "\n",
    "\n",
    "def method_file_id(method):\n",
    "    if method == 'idr':\n",
    "        return '1ReyXoGCfmcItHn9ClkwuyD_8mVYZ-BE2'\n",
    "    elif method == 'h3d-net':\n",
    "        return '1iwZ3cxJzq22zXb3hYL5DfcGWiEmOyjBW'\n",
    "    else:\n",
    "        raise ValueError(f'Method {method}')\n",
    "\n",
    "\n",
    "def download_reconstructions(token, method, local_dir):\n",
    "\n",
    "    method_dir = os.path.join(local_dir, method)\n",
    "    method_zip = os.path.join(local_dir, f'{method}.zip')\n",
    "    if os.path.exists(method_dir):\n",
    "        logger.info(\n",
    "            f'{method} reconstructions found at {method_dir} - Skipping download'\n",
    "        )\n",
    "        return method_dir\n",
    "    else:\n",
    "        logger.info(f'Downloading {method} results to {method_zip}')\n",
    "        create_parent_directory(method_zip)\n",
    "        download_file_from_google_drive(id=method_file_id(method),\n",
    "                                        destination=method_zip)\n",
    "\n",
    "    # Unzip file\n",
    "    logger.info(f'Unzipping results file to {method_dir}')\n",
    "    create_directory(method_dir)\n",
    "    with zipfile.ZipFile(method_zip, 'r') as zip_ref:\n",
    "        for member in tqdm(zip_ref.infolist(), desc='Extracting...'):\n",
    "            zip_ref.extract(member, method_dir, pwd=token.encode('utf-8'))\n",
    "\n",
    "    remove(method_zip)\n",
    "\n",
    "    return method_dir\n",
    "\n",
    "\n",
    "def main(h3ds_path, h3ds_token, method, output_dir):\n",
    "\n",
    "    # Create instance of h3ds and download it if not available\n",
    "    h3ds = H3DS(path=h3ds_path)\n",
    "    h3ds.download(token=h3ds_token)\n",
    "\n",
    "    # Download cached reconstruction results for selected method\n",
    "    recs_dir = os.path.join(output_dir, 'reconstructions')\n",
    "    method_dir = download_reconstructions(token=h3ds_token,\n",
    "                                          method=method,\n",
    "                                          local_dir=recs_dir)\n",
    "\n",
    "    # Evaluate `method` on all the scenes used in the h3d-net paper and store the metric\n",
    "    metrics_head = {}\n",
    "    metrics_face = {}\n",
    "    h3ds_scenes = h3ds.scenes(tags={'h3d-net'})\n",
    "    eval_dir = os.path.join(output_dir, 'evaluation', method)\n",
    "\n",
    "    for scene_id in h3ds_scenes:\n",
    "\n",
    "        metrics_head[scene_id] = {}\n",
    "        metrics_face[scene_id] = {}\n",
    "\n",
    "        h3ds_views_configs = h3ds.default_views_configs(scene_id)\n",
    "        for views_config_id in h3ds_views_configs:\n",
    "\n",
    "            logger.info(\n",
    "                f'Evaluating {method} reconstruction with {views_config_id} views from scene {scene_id}.'\n",
    "            )\n",
    "\n",
    "            # Get scene in millimiters\n",
    "            mesh_gt, images, masks, cameras = h3ds.load_scene(\n",
    "                scene_id, views_config_id)\n",
    "\n",
    "            # Load predicted 3D reconstruction.\n",
    "            mesh_pred = Mesh().load(\n",
    "                os.path.join(method_dir, f'{scene_id}_{views_config_id}.ply'))\n",
    "            landmarks_pred = None\n",
    "\n",
    "            # Evaluate scene. The `landmarks_pred` are optional and, if provided, they will be used\n",
    "            # for an initial alignment in the evaluation process. If not provided, it will be assumed\n",
    "            # that the predicted mesh is already coarsely aligned with the ground truth mesh.\n",
    "            chamfer_gt_pred, chamfer_pred_gt, mesh_gt, mesh_pred_aligned = \\\n",
    "                h3ds.evaluate_scene(scene_id, mesh_pred, landmarks_pred)\n",
    "\n",
    "            metrics_head[scene_id][views_config_id] = np.mean(chamfer_gt_pred)\n",
    "            logger.info(\n",
    "                f' > Chamfer distance full head (mm): {metrics_head[scene_id][views_config_id]}'\n",
    "            )\n",
    "            mesh_gt.save(\n",
    "                os.path.join(eval_dir, 'full_head',\n",
    "                             f'{scene_id}_{views_config_id}_gt.obj'))\n",
    "\n",
    "            # The chamfer computed from prediction to ground truth is only provided for\n",
    "            # visualization purporses (i.e. heatmaps).\n",
    "            mesh_pred_aligned.vertices_color = error_to_color(chamfer_pred_gt,\n",
    "                                                              clipping_error=5)\n",
    "            mesh_pred_aligned.save(\n",
    "                os.path.join(eval_dir, 'full_head',\n",
    "                             f'{scene_id}_{views_config_id}_pred.obj'))\n",
    "\n",
    "            # Evaluate reconstruction in the facial region, defined by a sphere of radius 95mm centered\n",
    "            # in the tip of the nose. In this case, a more fine alignment is performed, taking into account\n",
    "            # only the vertices from this region. This evaluation should be used when assessing methods\n",
    "            # that only reconstruct the frontal face area (i.e. Basel Face Bodel)\n",
    "            chamfer_gt_pred, chamfer_pred_gt, mesh_gt_region, mesh_pred_aligned = \\\n",
    "                h3ds.evaluate_scene(scene_id, mesh_pred, landmarks_pred, region_id='face_sphere')\n",
    "\n",
    "            # Note that in both cases we only report the chamfer distane computed from the ground truth\n",
    "            # to the prediction, since here we have control over the region where the metric is computed.\n",
    "            metrics_face[scene_id][views_config_id] = np.mean(chamfer_gt_pred)\n",
    "            logger.info(\n",
    "                f' > Chamfer distance face (mm): {metrics_face[scene_id][views_config_id]}'\n",
    "            )\n",
    "            mesh_gt_region.save(\n",
    "                os.path.join(eval_dir, 'face_sphere',\n",
    "                             f'{scene_id}_{views_config_id}_gt.obj'))\n",
    "\n",
    "            # Again, the chamfer computed from prediction to ground truth is only provided for\n",
    "            # visualization purporses (i.e. heatmaps).\n",
    "            mesh_pred_aligned.vertices_color = error_to_color(chamfer_pred_gt,\n",
    "                                                              clipping_error=5)\n",
    "\n",
    "            # For improved visualization the predicted mesh is cut to be inside the unit sphere of 95mm.\n",
    "            # Ideally one should use landmarks_pred but here we are using landmarks_true because the\n",
    "            # landmarks_pred are not available.\n",
    "            landmarks_true = h3ds.load_landmarks(scene_id)\n",
    "            mask_sphere = np.where(\n",
    "                np.linalg.norm(mesh_pred_aligned.vertices -\n",
    "                               mesh_gt.vertices[landmarks_true['nose_tip']],\n",
    "                               axis=-1) < 95)\n",
    "            mesh_pred_aligned = mesh_pred_aligned.cut(mask_sphere)\n",
    "\n",
    "            mesh_pred_aligned.save(\n",
    "                os.path.join(eval_dir, 'face_sphere',\n",
    "                             f'{scene_id}_{views_config_id}_pred.obj'))\n",
    "\n",
    "    # Show results per view\n",
    "    logger.info(f'Average Chamfer Distances for {method} as face / head in mm:')\n",
    "    for v in h3ds_views_configs:\n",
    "        metric_head = np.mean([metrics_head[s][v] for s in h3ds_scenes])\n",
    "        metric_face = np.mean([metrics_face[s][v] for s in h3ds_scenes])\n",
    "        logger.info(f'  > views: {v} - error: {metric_face} / {metric_head}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #parser = argparse.ArgumentParser(description='Exemplifies how to evaluate a method')\n",
    "    #parser.add_argument('--h3ds_path', help='H3DS dataset path', required=True)\n",
    "    #parser.add_argument('--h3ds_token', help='H3DS access token', required=True)\n",
    "    #parser.add_argument('--method', help='[idr, h3d-net]', default='h3d-net')\n",
    "    #parser.add_argument('--output_dir', help='Output directory to store the results', required=True)\n",
    "    \n",
    "    #argv = [\"\",\".\\h3ds\",\"4ce4d22168adeeefe6a1ec1d738fac4d\", \"h3d-net\", \".\\results\"]\n",
    "\n",
    "    #args = parser.parse_args(argv[1:])\n",
    "    main(h3ds_path='.\\h3ds',\n",
    "         h3ds_token='4ce4d22168adeeefe6a1ec1d738fac4d',\n",
    "         method='h3d-net',\n",
    "         output_dir='.\\results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7953fd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e026aa64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
